{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required python package and set the Cloudant credentials\n",
    "flightPredict is a helper package used to load data into RDD of LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import math\n",
    "!pip install --user --upgrade -e https://github.com/ibm-cds-labs/simple-data-pipe-connector-flightstats/raw/master/lib/python/flightPredict/dist/flightPredict-0.3.tar.gz\n",
    "import flightPredict\n",
    "flightPredict.sqlContext = sqlContext\n",
    "flightPredict.cloudantHost='XXXX'\n",
    "flightPredict.cloudantUserName='XXXX'\n",
    "flightPredict.cloudantPassword='XXXX'\n",
    "flightPredict.weatherUrl='XXXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data from training data set and print the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbName = \"<<Your db training set here >>\"\n",
    "cloudantdata = flightPredict.loadDataSet(dbName,\"training\")\n",
    "cloudantdata.cache()\n",
    "cloudantdata.printSchema()\n",
    "cloudantdata.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize classes in scatter plot based on 2 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flightPredict.scatterPlotForFeatures(cloudantdata, \\\n",
    "     \"departureWeather.temp\",\"arrivalWeather.temp\",\"Departure Airport Temp\", \"Arrival Airport Temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flightPredict.scatterPlotForFeatures(cloudantdata,\\\n",
    "     \"departureWeather.pressure\",\"arrivalWeather.pressure\",\"Departure Airport Pressure\", \"Arrival Airport Pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flightPredict.scatterPlotForFeatures(cloudantdata,\\\n",
    " \"departureWeather.wspd\",\"arrivalWeather.wspd\",\"Departure Airport Wind Speed\", \"Arrival Airport Wind Speed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the training data as an RDD of LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "computeClassification=(lambda x:x[0])\n",
    "trainingData = flightPredict.loadLabeledDataRDD(\"training\")\n",
    "print(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train multiple classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "logRegModel = LogisticRegressionWithLBFGS.train(trainingData.map(lambda lp: LabeledPoint(lp.label,\\\n",
    "      np.fromiter(map(lambda x: 0.0 if np.isnan(x) else x,lp.features.toArray()),dtype=np.double )))\\\n",
    "      , iterations=100, validateData=False, intercept=True)\n",
    "print(logRegModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes\n",
    "#NaiveBayes requires non negative features, set them to 0 for now\n",
    "modelNaiveBayes = NaiveBayes.train(trainingData.map(lambda lp: LabeledPoint(lp.label, \\\n",
    "                    np.fromiter(map(lambda x: x if x>0.0 else 0.0,lp.features.toArray()),dtype=np.int)\\\n",
    "               ))\\\n",
    "          )\n",
    "\n",
    "print(modelNaiveBayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree\n",
    "modelDecisionTree = DecisionTree.trainClassifier(trainingData.map(lambda lp: LabeledPoint(lp.label,\\\n",
    "      np.fromiter(map(lambda x: 0.0 if np.isnan(x) else x,lp.features.toArray()),dtype=np.double )))\\\n",
    "      , numClasses=3, categoricalFeaturesInfo={})\n",
    "print(modelDecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest\n",
    "modelRandomForest = RandomForest.trainClassifier(trainingData.map(lambda lp: LabeledPoint(lp.label,\\\n",
    "      np.fromiter(map(lambda x: 0.0 if np.isnan(x) else x,lp.features.toArray()),dtype=np.double )))\\\n",
    "      , numClasses=3, categoricalFeaturesInfo={},numTrees=100)\n",
    "print(modelRandomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Blind data from Cloudant database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbTestName=\"<<Your db Test set here>>\"\n",
    "testCloudantdata = flightPredict.loadDataSet(dbTestName,\"blind\")\n",
    "testCloudantdata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testData = flightPredict.loadLabeledDataRDD(\"blind\",computeClassification)\n",
    "flightPredict.runMetrics(trainingData,modelNaiveBayes,modelDecisionTree,logRegModel,modelRandomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the predictive model\n",
    "runModel(departureAirportCode, departureDateTime, arrivalAirportCode, arrivalDateTime)  \n",
    "Note: all DateTime must use UTC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from flightPredict import run\n",
    "run.useModels(modelNaiveBayes,modelDecisionTree,logRegModel,modelRandomForest)\n",
    "run.runModel('BOS', \"2016-02-08 20:15-0500\", 'LAX', \"2016-01-08 22:30-0500\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.4.1)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
